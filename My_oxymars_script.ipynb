{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "fab145c62319e31a41c9a6790a7fad7c720880be9303f3e3ea8a2856d3d97e4d"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikita-Barik/Oxymars-Project/blob/main/My_oxymars_script.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25f4b601"
      },
      "source": [
        "#Installing required Libraries\n",
        "!pip install bs4\n",
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "id": "25f4b601",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa702b62"
      },
      "source": [
        "#Importing required libraries/function/class\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import time\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"
      ],
      "id": "fa702b62",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69dc9658"
      },
      "source": [
        "# Variables containing perticular job details\n",
        "#'Enter Main Company link(Having 25 entries each) :\n",
        "complink = ['https://www.monsterindia.com/search/oloop-technology-solutions-private-limited-233469-jobs-career?searchId=9c430de5-dc38-485e-b399-b0a427395cc6']\n",
        "\n",
        "#'Enter .CSV filename. i.e., short Company name :      \n",
        "filename = 'oloop.csv'    \n",
        "\n",
        "#'Enter given email address :                                                                                                                                      \n",
        "email_address = 'oloogysolutiochnolovatelimitednspriptejobsandcareers@sunisbrite.com'      \n",
        "\n",
        "#'Enter Company UserName you entered :                                                                                  \n",
        "username = 'olaoup'                      \n",
        "\n",
        "#'Enter Company name :                                                                                                                      \n",
        "company_name = 'Technology Solutions Private Limited'\n",
        "\n",
        "#'Check total number of jobs and enter here :\n",
        "total_jobs = 627"
      ],
      "id": "69dc9658",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a590f606"
      },
      "source": [
        "#Calculating total no. of pages to scrap according to the total jobs(25 jobs per page)\n",
        "string = complink[0]\n",
        "loc = string.find('jobs-career')\n",
        "loc = loc + 11\n",
        "last_page = 1\n",
        "if total_jobs > 25:\n",
        "    if total_jobs % 25 == 0:\n",
        "        x = int(total_jobs//25)\n",
        "    else:\n",
        "        x = int(total_jobs//25)\n",
        "        x = x+1\n",
        "\n",
        "    for i in range(2, x+1):\n",
        "        page = complink[0][0:loc] + f'-{i}' + complink[0][loc:]\n",
        "        complink.append(page)\n",
        "        last_page = i\n",
        "print(complink)\n",
        "print(complink[0:last_page])"
      ],
      "id": "a590f606",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54aaf182"
      },
      "source": [
        "#Definiotions of all required functions\n",
        "\n",
        "# 1 of 2\n",
        "def find_state(city):\n",
        "    if city[0] == 'Mumbai' or city[0] == 'Pune' or city[0] == 'Navi Mumbai' or city[0] == 'Thar' or city[0] == 'Mumbai City' or city[0] == 'Aurangabad' or city[0] == 'Nagpur' or city[0] == 'Dhule' or city[0] == 'Nashik' or city[0] == 'Karad' or city[0] == 'Kolhapur' or city[0] == 'Wardha' or city[0] == 'Yavatmal' or city[0] == 'Pandharpur' or city[0] == 'Hingoli' or city[0] == 'Sangola' or city[0] == 'Gondia' or city[0] == 'Shahapur' or city[0] == 'Chandrapur' or city[0] == 'Satara' or city[0] == 'Shirpur' or city[0] == 'Ahmadnagar' or city[0] == 'Solapur' or city[0] == 'Bhusawal' or city[0] == 'Ratnagiri' or city[0] == 'Jalgaon' or city[0] == 'Osmanabad' or city[0] == 'Amravati':\n",
        "        state = 'Maharashtra'\n",
        "    elif city[0] == 'Noida' or city[0] == 'Lucknow' or city[0] == 'Ghaziabad' or city[0] == 'Mathura' or city[0] == 'Allahabad' or city[0] == 'Agra' or city[0] == 'Aligarh' or city[0] == 'Etawah' or city[0] == 'Moradabad' or city[0] == 'Varanasi' or city[0] == 'Kanpur' or city[0] == 'Bareilly':\n",
        "        state = 'Uttar Pradesh'\n",
        "    elif city[0] == 'Kochi' or city[0] == 'Cochin' or city[0] == 'Ernakulam' or city[0] == 'Kozhikode' or city[0] == 'Thiruvananthapuram' or city[0] == 'Palakkad' or city[0] == 'Kannur' or city[0] == 'Kottayam' or city[0] == 'Alappuzha':\n",
        "        state = 'Kerala'\n",
        "    elif city[0] == 'Bengaluru' or city[0] == 'Bijapur' or city[0] == 'Kolar' or city[0] == 'Bangalore' or city[0] == 'Mysore' or city[0] == 'Hospet' or city[0] == 'Bidar' or city[0] == 'Karwar' or city[0] == 'Dharwad' or city[0] == 'Tumkur' or city[0] == 'Pavagada' or city[0] == 'Bagalkot' or city[0] == 'Belgaum' or city[0] == 'Udupi' or city[0] == 'Gokak' or city[0] == 'Mandya' or city[0] == 'Hubli' or city[0] == 'Gadag' or city[0] == 'Raichur' or city[0] == 'Hoskote' or city[0] == 'Chitradurga' or city[0] == 'Gulbarga' or city[0] == 'Kolar':\n",
        "        state = 'Karnataka'\n",
        "    elif city[0] == 'Chennai' or city[0] == 'Coimbatore' or city[0] == 'Kovilpatti' or city[0] == 'Hosur' or city[0] == 'Tiruvallur' or city[0] == 'Madurai' or city[0] == 'Salem' or city[0] == 'Pudukkottai' or city[0] == 'Kanchipuram' or city[0] == 'Cuddalore' or city[0] == 'Ramanathapuram' or city[0] == 'Tirunelveli' or city[0] == 'Annur' or city[0] == 'Thanjavur' or city[0] == 'Erode' or city[0] == 'Dindigul' or city[0] == 'Karaikudi' or city[0] == 'Tiruppur' or city[0] == 'Trichy' or city[0] == 'Rajapalayam' or city[0] == 'Neyveli' or city[0] == 'Vellore' or city[0] == 'Palani' or city[0] == 'Dharmapuri':\n",
        "        state = 'Tamil Nadu'\n",
        "    elif city[0] == 'Ahmedabad' or city[0] == 'Junagadh' or city[0] == 'Vadodara' or city[0] == 'Navsari' or city[0] == 'Bharuch' or city[0] == 'Valsad' or city[0] == 'Surat' or city[0] == 'Mehsana' or city[0] == 'Himatnagar' or city[0] == 'Anand' or city[0] == 'Bardoli' or city[0] == 'Dhoraji' or city[0] == 'Bhuj' or city[0] == 'Palanpur' or city[0] == 'Rajula' or city[0] == 'Godhra' or city[0] == 'Vapi' or city[0] == 'Dabhoi' or city[0] == 'Gandhinagar' or city[0] == 'Patan' or city[0] == 'Ankleshwar' or city[0] == 'Nadiad' or city[0] == 'Jamnagar' or city[0] == 'Rajkot' or city[0] == 'Gandhidham':\n",
        "        state = 'Gujarat'\n",
        "    elif city[0] == 'Gurugram' or city[0] == 'Gurgaon' or city[0] == 'Hisar' or city[0] == 'Panipat' or city[0] == 'Rohtak' or city[0] == 'Bahadurgarh' or city[0] == 'Karnal' or city[0] == 'Ambala' or city[0] == 'Sonipat' or city[0] == 'Jind' or city[0] == 'Bhiwani' or city[0] == 'Sirsa':\n",
        "        state = 'Haryana'\n",
        "    elif city[0] == 'Kolkata' or city[0] == 'Salt' or city[0] == 'Siliguri' or city[0] == 'Durgapur' or city[0] == 'Burdwan' or city[0] == 'Kharagpur':\n",
        "        state = 'West Bengal'\n",
        "    elif city[0] == 'Hyderabad' or city[0] == 'Secunderabad' or city[0] == 'Nalgonda' or city[0] == 'Warangal' or city[0] == 'Mahbubnagar' or city[0] == 'Karimnagar':\n",
        "        state = 'Telangana'\n",
        "    elif city[0] == 'Udaipur' or city[0] == 'Jaipur' or city[0] == 'Kishangarh' or city[0] == 'Hindaun' or city[0] == 'Nagar' or city[0] == 'Nathdwara' or city[0] == 'Kotputli' or city[0] == 'Raisinghnagar' or city[0] == 'Anupgarh' or city[0] == 'Pokaran' or city[0] == 'Jodhpur' or city[0] == 'Barmer' or city[0] == 'Banswara' or city[0] == 'Rawatsar' or city[0] == 'Nokha' or city[0] == 'Baran' or city[0] == 'Gangapur' or city[0] == 'Ajmer' or city[0] == 'Balotra' or city[0] == 'Sikar' or city[0] == 'Ganganagar' or city[0] == 'Bhilwara' or city[0] == 'Kota':\n",
        "        state = 'Rajasthan'\n",
        "    elif city[0] == 'Panchkula' or city[0] == 'Chandigarh':\n",
        "        state = 'Chandigarh'\n",
        "    elif city[0] == 'Ludhiana' or city[0] == 'Abohar'or city[0] == 'Amritsar' or city[0] == 'Rajpura' or city[0] == 'Gurdaspur' or city[0] == 'Patiala' or city[0] == 'Kapurthala' or city[0] == 'Bhatinda' or city[0] == 'Jalandhar':\n",
        "        state = 'Punjab'\n",
        "    elif city[0] == 'Motihari' or city[0] == 'Muzaffarpur' or city[0] == 'Patna' or city[0] == 'Gaya' or city[0] == 'Arrah' or city[0] == 'Bhagalpur' or city[0] == 'Madhubani' or city[0] == 'Saharsa' or city[0] == 'Jhanjharpur' or  city[0] == 'Chhapra' or city[0] == 'Chapra':\n",
        "        state = 'Bihar'\n",
        "    elif city[0] == 'Rourkela' or city[0] == 'Sambalpur' or city[0] == 'Bhubaneswar' or city[0] == 'Puri' or city[0] == 'Deogarh' or city[0] == 'Bargarh' or city[0] == 'Jeypore' or city[0] == 'Bhadrak' or city[0] == 'Berhampur' or city[0] == 'Cuttack':\n",
        "        state = 'Odisha'\n",
        "    elif city[0] == 'Shillong':\n",
        "        state = 'Meghalaya'\n",
        "    elif city[0] == 'Jamshedpur' or city[0] == 'Ranchi' or city[0] == 'Deoghar' or city[0] == 'Dhanbad':\n",
        "        state = 'Jharkhand'\n",
        "    elif city[0] == 'Bilaspur' or city[0] == 'Bhatapara' or city[0] == 'Raipur' or city[0] == 'Korba':\n",
        "        state = 'Chhattisgarh'    \n",
        "    elif city[0] == 'Dhubri' or city[0] == 'Guwahati' or city[0] == 'Jorhat' or city[0] == 'Dibrugarh' or city[0] == 'Silchar':\n",
        "        state = 'Assam'\n",
        "    elif city[0] == 'Rewa' or city[0] == 'Gwalior' or city[0] == 'Satna' or city[0] == 'Bhopal' or city[0] == 'Hoshangabad' or city[0] == 'Indore' or city[0] == 'Chhindwara' or city[0] == 'Guna' or city[0] == 'Sehore' or city[0] == 'Jabalpur' or city[0] == 'Mandla' or city[0] == 'Mauganj' or city[0] == 'Ujjain' or city[0] == 'Dhar' or city[0] == 'Mandsaur' or city[0] == 'Dewas':\n",
        "        state = 'Madhya Pradesh'\n",
        "    elif city[0] == 'Tirupati' or city[0] == 'Bhimavaram' or city[0] == 'Nellore' or city[0] == 'Kadapa' or city[0] == 'Chittoor' or city[0] == 'Rajahmundry' or city[0] == 'Ongole' or city[0] == 'Tanuku' or city[0] == 'Visakhapatnam' or city[0] == 'Srikakulam' or city[0] == 'Dharmavaram' or city[0] == 'Eluru' or city[0] == 'Adoni' or city[0] == 'Kurnool' or city[0] == 'Guntakal' or city[0] == 'Proddatur' or city[0] == 'Anantapur' or city[0] == 'Vijayawada' or city[0] == 'Kakinada':\n",
        "        state = 'Andhra Pradesh'   \n",
        "    elif city[0] == 'Solan' or city[0] == 'Mandi':\n",
        "        state = 'Himachal Pradesh'\n",
        "    elif city[0] == 'Pondicherry':\n",
        "        state = 'Pondicherry'  \n",
        "    elif city[0] == 'Dehradun' or city[0] == 'Nainital' or city[0] == 'Kichha' or city[0] == 'Roorkee':\n",
        "        state = 'Uttarakhand' \n",
        "    elif city[0] == 'Udhampur' or city[0] == 'Jammu':\n",
        "        state = 'Kashmir'  \n",
        "    elif city[0] == 'Madgaon': \n",
        "        state = 'Goa'    \n",
        "    elif city[0] == 'Agartala':\n",
        "        state = 'Tripura' \n",
        "    elif city[0] == 'Daman':\n",
        "        state = 'Daman and Diu'\n",
        "    elif city[0] == 'Gangtok':\n",
        "        state = 'Sikkim'\n",
        "    elif city[0] == 'Silvassa':\n",
        "        state = 'Dadra and Nagar Haveli'     \n",
        "    else:\n",
        "        state = 'Delhi'\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "# 2 of 2\n",
        "def identify_job_sector(x):\n",
        "    if 'Human' in x or 'Recruitment' in x or 'Human Resources' in x or 'Admin' in x:\n",
        "        x = 'HR Jobs'\n",
        "    elif 'Digital Marketing' in x or 'Marketing & Communications' in x or 'Marketing Research & Analysis' in x or 'Advertising' in x or 'Buyer' in x:\n",
        "        x = 'Marketing Jobs'  \n",
        "    elif 'Health' in x or 'Hospitals' in x or 'Healthcare' in x or 'Diagnostics' in x or 'Personal Care' in x:\n",
        "        x = 'Health Care Jobs'\n",
        "    elif 'Customer Service' in x:\n",
        "        x = 'Consultant Jobs' \n",
        "    elif 'Finance & Accounts' in x:\n",
        "        x = 'Accounting Jobs'\n",
        "    elif 'Pharmaceutical' in x:\n",
        "        x = 'Pharma Jobs'\n",
        "    elif 'Application' in x:\n",
        "        x = 'Application Programming Jobs'\n",
        "    elif 'Product Management' in x:\n",
        "        x = 'Maintenance Jobs'\n",
        "    elif 'Oil & Gas' in x or 'Engineering - Electronics' in x or 'Engineering - Chemical' in x or 'Manufacturing' in x or 'Engineering - Electrical' in x:\n",
        "        x = 'Engineering'\n",
        "    elif 'Retail Chains' in x or 'Sales - Telesales' in x or 'Sales - Financial Services (Insurance' in x or 'Sales - Retail' in x:\n",
        "        x = 'Sales'\n",
        "    elif 'Telecom Software' in x:\n",
        "        x = 'Telecom Software Jobs'\n",
        "    elif 'Banking' in x:\n",
        "        x = 'Bank Jobs'\n",
        "    elif 'System' in x:\n",
        "        x = 'System Programming Jobs'\n",
        "    elif 'Site' in x:\n",
        "        x = 'Site Engineering Jobs'\n",
        "    elif 'Network' in x:\n",
        "        x = 'Network administrator Jobs'\n",
        "    elif 'Interior' in x or 'Architecture' in x:\n",
        "        x = 'Interior Design Jobs'\n",
        "    elif 'IT' in x or 'Information' in x or 'IT- Hardware' in x:\n",
        "        x = 'IT Jobs'\n",
        "    elif 'Export' in x:\n",
        "        x = 'Export Import'\n",
        "    elif 'Graphic' in x or 'Arts' in x:\n",
        "        x = 'Graphic Designer Jobs'\n",
        "    elif 'Hardwer' in x:\n",
        "        x = 'Hardwer & Networking Jobs'\n",
        "    elif 'BPO' in x:\n",
        "       x = 'BPO / Call Centre'\n",
        "    elif 'Business' in x:\n",
        "        x = 'Business Intelligence Jobs'\n",
        "    elif 'Client' in x:\n",
        "        x = 'Client Server Jobs'\n",
        "    elif 'Content' in x or 'Journalism' in x:\n",
        "        x = 'Content Writing'\n",
        "    elif 'Corporate' in x:\n",
        "        x = 'Corporate Planning Jobs'\n",
        "    elif 'Education' in x:\n",
        "        x = 'Education Training'  \n",
        "    elif  'Marine Services' in x:\n",
        "        x = 'Merchandiser'\n",
        "    elif 'Hotels' in x:\n",
        "        x = 'Hotel Jobs'\n",
        "    elif 'Accounting' in x or 'Airline' in x or 'Automobile' in x or 'Bank' in x or 'Analytics' in x or 'Consultant' in x or 'DBA' in x or 'Ecommerce' in x or 'EDP' in x:\n",
        "        x = x\n",
        "    elif 'Film' in x or 'Hotel' in x or 'Legal' in x or 'Logistics' in x or 'Pharma' in x:\n",
        "        x = x\n",
        "    elif 'Mainframe' in x or 'Maintenance' in x or 'Marketing' in x or 'Middleware' in x or 'Mobile' in x or 'Packaging' in x or 'Pharma' in x or 'Secretary' in x:\n",
        "        x = x\n",
        "    elif 'Security' in x or 'Shipping' in x or 'Testing' in x or 'VLSI' in x or 'ERP' in x:\n",
        "        x = x\n",
        "    else:\n",
        "        x = 'IT Jobs'\n",
        "    \n",
        "    return x"
      ],
      "id": "54aaf182",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLCESJw7PUAH"
      },
      "source": [
        "#                          ***Freshly(from 1st page, i.e., given complink) Scrapping Should be done from this cell....***\n",
        "\n",
        "\n",
        "#temp list to store scraped data\n",
        "data = []"
      ],
      "id": "zLCESJw7PUAH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fniNsm8d4JIH"
      },
      "source": [
        "#                 ***Scraping Should be done from this cell, if you given range for scraping.\n",
        "#                                                        i.e., you scraped some pages and now starting scraping from some page, other than 1st....***\n",
        "\n",
        "#Enter the Page where on which got error...\n",
        "#Defaultly 'scrapping_start_page = 1' to start from your given complink\n",
        "scraping_start_page = 1\n",
        "#last_page = 10                               #last page for scraping excluding jobs of given page number, remove '#' symbol & replace 10 to certain page number...\n"
      ],
      "id": "fniNsm8d4JIH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ce8fc40"
      },
      "source": [
        "#Scraping data from Job URL\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "scraping_start_page = scraping_start_page - 1\n",
        "data_length = 0\n",
        "\n",
        "for lnk in complink[scraping_start_page:last_page]:      \n",
        "    \n",
        "    chrome_options = webdriver.ChromeOptions()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    \n",
        "    driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "\n",
        "    page = complink.index(lnk) + 1\n",
        "    print(f'Page - {page}')\n",
        "    monsterindia_responce_checker_out = 0\n",
        "    monsterindia_responce_checker_in = 0\n",
        "\n",
        "    for i in range(3):\n",
        "        try:\n",
        "            driver.get(lnk)\n",
        "        except WebDriverException:\n",
        "            print(f\"MonsterIndia Not Responding, Checked {i+1} time...(After 3rd try execution will be terminated)\")\n",
        "            monsterindia_responce_checker_out = monsterindia_responce_checker_out + 1\n",
        "            time.sleep(1)\n",
        "        time.sleep(1)\n",
        "    time.sleep(2)\n",
        "    if monsterindia_responce_checker_out >= 3:\n",
        "        print('Cell Execution Terminated...')\n",
        "        break\n",
        "\n",
        "    resp = driver.page_source\n",
        "    soup = BeautifulSoup(resp, 'html.parser')\n",
        "    link_list = soup.select('[class=\"job-tittle\"] h3 a')\n",
        "    \n",
        "    for link in link_list:\n",
        "        url = link.get('href')\n",
        "        try:\n",
        "            time.sleep(1)\n",
        "            driver.get(url)\n",
        "            time.sleep(1)\n",
        "        except:\n",
        "            print(\"MonsterIndia.com Not Responding.\")\n",
        "            print('Cell Execution Terminated...')\n",
        "            monsterindia_responce_checker_in = monsterindia_responce_checker_in + 1\n",
        "            break\n",
        "\n",
        "        resp_info = driver.page_source\n",
        "        soup_info = BeautifulSoup(resp_info, 'html.parser')\n",
        "        job_details = soup_info.select('.job-details-wrapper')\n",
        "\n",
        "        for info in job_details:\n",
        "            job_title = (info.select('h1')[0].getText()).strip()\n",
        "            location = (info.select('.loc.jd-loc a')[0].getText()).strip()\n",
        "            location = location.split(' / ')[0]\n",
        "            try:\n",
        "                if location == 'India':\n",
        "                    location = (info.select('.loc.jd-loc a')[1].getText()).strip()\n",
        "                    location = location.split(' / ')[0]\n",
        "            except IndexError:  \n",
        "                pass \n",
        "\n",
        "            CITY = location.replace(',', '',)\n",
        "            city = location.split(',')\n",
        "            state = find_state(city)\n",
        "            experience = (info.select('.exp.col-xxs-12.col-sm-3.text-ellipsis span small')[0].getText()).strip().replace(' years', '').split('-')\n",
        "            try:\n",
        "                if experience[0] == 'Not Specified':\n",
        "                    years = 'Fresh'\n",
        "                elif experience[0] == 'Fresher':\n",
        "                    years = 'Fresh'\n",
        "                elif int(experience[0]) == 0 or int(experience[1]) == 0:\n",
        "                    years = 'Fresh'\n",
        "                elif int(experience[0]) == 0 and int(experience[1]) == 1:\n",
        "                    years = 'Less Than 1 Year'\n",
        "                elif int(experience[0]) >= 8:\n",
        "                    years = '8 Years +'\n",
        "                elif int(experience[0]) >= 2 and int(experience[1]) <= 7:\n",
        "                    years = experience[0] + ' Years'\n",
        "                else: years = 'Fresh'\n",
        "            except IndexError:\n",
        "                years = 'Fresh'\n",
        "                continue\n",
        "\n",
        "            description = info.select('.job-description-content .jd-text')[0].getText().strip().replace('<br/>', '\\n').replace(':', ':\\n').replace('\\t', '').replace('*', '\\n*')\n",
        "            description += '\\nJob Details\\n'\n",
        "            job_sector = None\n",
        "            key_skills = ''\n",
        "            for count, details in enumerate(info.find_all('div', class_ ='job-detail-list')):\n",
        "                dt_heading = details.find('div', class_ = 'dt-heading').text.replace('\\t', '')\n",
        "                dt_content = details.find('div', class_ = 'dt-content').text.replace('\\t', '')\n",
        "                description += f'\\n{dt_heading}\\n{dt_content}'\n",
        "                #algorithm\n",
        "                try:\n",
        "                    if count == 2:\n",
        "                        function = details.find('div', class_ = 'dt-content').text.replace('\\t', '').split('/')\n",
        "                        if 'Other' in function or 'Others' in function:\n",
        "                            job_sector = 'IT Jobs'\n",
        "                        else:\n",
        "                            job_sector = function[0]\n",
        "                    job_sector=(job_sector.split(',')[0]).strip()\n",
        "                    if count == 4:\n",
        "                        description += '\\nKey Skills\\n'\n",
        "                        for index, skill in enumerate(details.find_all('span', class_ = 'round-card mb5 grey-link')):\n",
        "                            description += f' ➼ {skill.text}\\n'\n",
        "                            if index > 4:\n",
        "                                break\n",
        "                            key_skills += skill.text + ', '\n",
        "                        continue\n",
        "                except AttributeError:\n",
        "                    continue\n",
        "            if key_skills == \"\":\n",
        "                key_skills= ' '\n",
        "            \n",
        "            employment = (info.select('#jobDets [class=\"card-panel\"] > div:nth-of-type(1) .dt-content')[0].getText()).strip()\n",
        "            #industry = (info.select('#jobDets [class=\"card-panel\"] > div:nth-child(2) .dt-content')[0].getText()).strip()\n",
        "            #function = (info.select('#jobDets [class=\"card-panel\"] > div:nth-child(3) .dt-content')[0].getText()).strip()\n",
        "            #skills = (info.select('#jobDets [class=\"card-panel\"] > div:nth-child(4) .dt-content')[0].getText()).strip()\n",
        "            min_salary, max_salary = '', ''\n",
        "            try:\n",
        "                salary = (info.select('.package')[0].getText()).strip()\n",
        "                salary = salary.replace(' ', '').split('-')\n",
        "                if salary[0] == 'NotSpecified':\n",
        "                    min_salary += salary[1]\n",
        "                else:\n",
        "                    min_salary += salary[0]\n",
        "                max_salary += salary[1]\n",
        "            except:\n",
        "                salary = ''\n",
        "            if min_salary == '':\n",
        "                min_salary= ' '\n",
        "            if max_salary == '':\n",
        "                max_salary= ' '\n",
        "\n",
        "            temp = {\n",
        "                'Job Title': job_title,\n",
        "                'Location': location,\n",
        "                'State': state,\n",
        "                'CITY': CITY,\n",
        "                'City': city[0],\n",
        "                'Experience': years,\n",
        "                'Description': description,\n",
        "                'Employment': employment,\n",
        "                'Job Sector':job_sector,\n",
        "                'Key Skills': key_skills,\n",
        "                #'Industry':industry,\n",
        "                #'Function':function,\n",
        "                #'Skills': skills,\n",
        "                'Min Salary': min_salary,\n",
        "                'Max Salary': max_salary\n",
        "            }\n",
        "            \n",
        "            data.append(temp)\n",
        "            data_length = len(data)\n",
        "            print(f\"{data_length} ====> {temp}\")\n",
        "            \n",
        "    if monsterindia_responce_checker_in >= 1:\n",
        "        print(f'Start scraping from current page againg and after csv created just delete some duplicate jobs in range-{(page-1)*25} to last scrapped job {data_length}')\n",
        "        break\n",
        "    print(f'All job on page-{page} scrapped...\\n')\n",
        "    driver.quit()"
      ],
      "id": "5ce8fc40",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79316c65"
      },
      "source": [
        "#Creating CSV file to store scrapped data\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(filename,index=False,header=True)\n",
        "data_list = pd.read_csv(filename).values.tolist()\n",
        "len(data_list)"
      ],
      "id": "79316c65",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS6oljVQ4xM4"
      },
      "source": [
        "#                                        ---------------- Start Posting from this cell ----------------       \n",
        "                # This cell isn't actually posting job, \n",
        "                # this cell only holds the code which we use in next cell to post jobs on client website - Oxymars.com\n",
        "\n",
        "\n",
        "#Posting Function defined\n",
        "def posting_failed(filename_failed, try_, posting_start, last_posting):\n",
        "\n",
        "    #Reading CSV file\n",
        "    data_list = pd.read_csv(filename_failed).values.tolist()\n",
        "\n",
        "    if posting_start <= 2:\n",
        "        posting_start = 0\n",
        "    elif posting_start > 2:\n",
        "        posting_start = posting_start - 2\n",
        "\n",
        "    if try_ != 0:\n",
        "        last_posting = len(data_list) + 1\n",
        "    last_posting = last_posting - 1\n",
        "\n",
        "\n",
        "    #Variables created for Un-posted Job record\n",
        "    post_no = 0\n",
        "    post_count = 0\n",
        "    post_record = {}\n",
        "    fail_count = 0\n",
        "    fail_countt = 0\n",
        "    fail_record = {}\n",
        "    fail_index = []\n",
        "\n",
        "    #Posting Jobs form CSV file\n",
        "    for i in range(posting_start, last_posting):          \n",
        "        warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "        chrome_options = webdriver.ChromeOptions()\n",
        "        chrome_options.add_argument('--headless')\n",
        "        chrome_options.add_argument('--no-sandbox')\n",
        "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "        another_options = webdriver.ChromeOptions()\n",
        "        another_options.add_argument('--start-maximized')\n",
        "        another_options.add_argument('--incognito')\n",
        "        another_options.add_argument('--disable-gpu')\n",
        "        another_options.add_argument('--disable-geolocation')\n",
        "        another_options.add_argument('--disable-extensions')\n",
        "\n",
        "        another_driver = webdriver.Chrome('chromedriver',chrome_options=chrome_options) \n",
        "\n",
        "        try:\n",
        "            another_driver.get('https://oxymars.com/india/post-new-job')\n",
        "            time.sleep(2)\n",
        "            \n",
        "            # job title\n",
        "            another_driver.find_element_by_id('ad-posting-title').send_keys(data_list[i][0])\n",
        "        except:\n",
        "            print(f\"Error Occured at job row-{i+2} in CSV due to OXY-MARS website isn't responding\")\n",
        "            fail_countt = -1\n",
        "            print(\"Cell Execution Terminated...\")\n",
        "            break\n",
        "\n",
        "        #Job description\n",
        "        if 10000 < len(data_list[i][6]):\n",
        "            data_list[i][6] = data_list[i][6][:9950]\n",
        "            pos = data_list[i][6].rfind('.')\n",
        "            data_list[i][6] = data_list[i][6][:pos+1]\n",
        "        data_list[i][6] = data_list[i][6].replace('\t',' ')\n",
        "        another_driver.switch_to.frame(\"job_detail_ifr\") # we need to change to frame in order to see the html elements/attribute\n",
        "        another_driver.find_element_by_id('tinymce').send_keys(data_list[i][6]) # enter full description\n",
        "\n",
        "        another_driver.switch_to.default_content() # switch to main page \n",
        "\n",
        "        #email address\n",
        "        another_driver.find_element_by_name('reg_user_email').send_keys(email_address)\n",
        "        \n",
        "        #username   \n",
        "        another_driver.find_element_by_name('reg_user_uname').send_keys(username)\n",
        "        \n",
        "        #company name\n",
        "        another_driver.find_element_by_name('pt_user_organization').send_keys(company_name)\n",
        "\n",
        "        #job sector\n",
        "        sector = identify_job_sector(data_list[i][8])\n",
        "        another_driver.find_element_by_id('job-sector-selectized').send_keys(sector)\n",
        "        another_driver.find_element_by_id('job-sector-selectized').send_keys(Keys.ENTER)\n",
        "\n",
        "        #job type\n",
        "        another_driver.find_element_by_id('job-type-selectized').send_keys(data_list[i][7])\n",
        "        another_driver.find_element_by_id('job-type-selectized').send_keys(Keys.ENTER)\n",
        "\n",
        "        #skills here\n",
        "        data_list[i][9] = data_list[i][9].replace('\t','')\n",
        "        another_driver.find_element_by_xpath('//*[@id=\"job-skills\"]/li/input').send_keys(data_list[i][9])\n",
        "\n",
        "        #salary\n",
        "        another_driver.find_element_by_name('job_salary').send_keys(data_list[i][10])\n",
        "        another_driver.find_element_by_name('job_max_salary').send_keys(data_list[i][10])\n",
        "\n",
        "        #other info\n",
        "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[1]/div/div/div[1]/input').send_keys('Others')\n",
        "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[1]/div/div/div[1]/input').send_keys(Keys.ENTER)\n",
        "        \n",
        "        # experiece\n",
        "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[2]/div/div/div[1]/input').send_keys(data_list[i][5])\n",
        "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[2]/div/div/div[1]/input').send_keys(Keys.ENTER)\n",
        "\n",
        "        #gender\n",
        "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[3]/div/div/div[1]/input').send_keys('Any')\n",
        "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[3]/div/div/div[1]/input').send_keys(Keys.ENTER)\n",
        "        \n",
        "        #qualifications \n",
        "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[4]/div/div/div[1]/input').send_keys(\"Degree Bachelor\")\n",
        "        another_driver.find_element_by_xpath('//*[@id=\"job-posting-form\"]/div[2]/ul/li[4]/div/div/div[1]/input').send_keys(Keys.ENTER)\n",
        "\n",
        "        #country  \n",
        "        z = 0 \n",
        "        while True:\n",
        "            z += 1\n",
        "            if z > 32:\n",
        "                fail_countt = -1\n",
        "                break     \n",
        "            time.sleep(5)\n",
        "            try:\n",
        "                another_driver.find_element_by_xpath('//*[@id=\"countryId-selectized\"]').send_keys('India')\n",
        "                another_driver.find_element_by_xpath('//*[@id=\"countryId-selectized\"]').send_keys(Keys.ENTER)\n",
        "                break\n",
        "            except:\n",
        "                pass\n",
        "        if fail_countt == -1:\n",
        "            print(f\"Error Occured because to OXY-MARS website isn't responding\")\n",
        "            print(\"Cell Exicution Terminated at country...\")\n",
        "            break\n",
        "\n",
        "        #state    \n",
        "        z = 0\n",
        "        while True:\n",
        "            z += 1\n",
        "            if z > 32:\n",
        "                fail_countt = -1\n",
        "                break  \n",
        "            time.sleep(5)\n",
        "            try: \n",
        "                another_driver.find_element_by_xpath('//*[@id=\"stateId-selectized\"]').send_keys(data_list[i][2]) \n",
        "                another_driver.find_element_by_xpath('//*[@id=\"stateId-selectized\"]').send_keys(Keys.ENTER)\n",
        "                break\n",
        "            except:\n",
        "                pass\n",
        "        if fail_countt == -1:\n",
        "            print(f\"Error Occured because to OXY-MARS website isn't responding\")\n",
        "            print(\"Cell Exicution Terminated at State...\")\n",
        "            break\n",
        "\n",
        "        #city\n",
        "        z = 0\n",
        "        while True:\n",
        "            z += 1\n",
        "            if z > 32:\n",
        "                fail_countt = -1\n",
        "                break  \n",
        "            time.sleep(5)\n",
        "            try:\n",
        "                if data_list[i][2] == 'Delhi':\n",
        "                    pass\n",
        "                elif data_list[i][2] == 'Orrisa':\n",
        "                    pass\n",
        "                elif data_list[i][2] == 'Jammu Kashmir':\n",
        "                    pass\n",
        "                else:    \n",
        "                    another_driver.find_element_by_xpath('//*[@id=\"cityId-selectized\"]').send_keys(data_list[i][4])\n",
        "                    another_driver.find_element_by_xpath('//*[@id=\"cityId-selectized\"]').send_keys(Keys.ENTER)\n",
        "                break\n",
        "            except:\n",
        "                pass\n",
        "        if fail_countt == -1:\n",
        "            print(f\"Error Occured because to OXY-MARS website isn't responding\")\n",
        "            print(\"Cell Exicution Terminated at City...\")\n",
        "            break\n",
        "\n",
        "        #Full Address\n",
        "        CITY=data_list[i][3]\n",
        "        complete_address = f'{CITY}, India'\n",
        "        if 'India' in CITY:\n",
        "            complete_address = CITY\n",
        "        another_driver.find_element_by_name('jobsearch_field_location_address').send_keys(complete_address)\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                time.sleep(2)\n",
        "                another_driver.find_element_by_name('terms_cond_check').click()\n",
        "                time.sleep(2)\n",
        "                another_driver.find_element_by_css_selector('input[type=\"submit\"]').click()\n",
        "                break\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "        time.sleep(10)\n",
        "\n",
        "        try:\n",
        "            soup = BeautifulSoup(another_driver.page_source, 'html.parser')\n",
        "            confirmation = (soup.find('div', class_ = 'jobsearch-employer-confitmation').h2).text.replace(' ','')\n",
        "            if confirmation == 'Thankyouforsubmitting':\n",
        "                post_no = post_no + 1\n",
        "                print(f'{post_no}.Posting job of row no.{i+2} from CSV file done...')\n",
        "                post_count = post_count+1\n",
        "                post_record[i+2] = data_list[i][0]\n",
        "            else:\n",
        "                print(f'Job of row-{i+2} {data_list[i][0]} in CSV file is not posted. Just wait, posting next job********in*******\\n')\n",
        "                fail_index.append(i)\n",
        "                fail_record[i+2] = data_list[i][0]\n",
        "                fail_count = fail_count+1   \n",
        "        except AttributeError:\n",
        "            print(f'\\nJob of row-{i+2} {data_list[i][0]} in CSV file is not posted. Just wait, posting next job********out********\\n')\n",
        "            fail_index.append(i)\n",
        "            fail_record[i+2] = data_list[i][0]\n",
        "            fail_count = fail_count+1\n",
        "\n",
        "        another_driver.quit()\n",
        "\n",
        "    print(f'\\nTotal No of Jobs Posted - {post_count}')\n",
        "    print('list of Jobs successfully Posted', post_record)\n",
        "    print(f'\\nTotal No of Jobs Failed to Post - {fail_count}')\n",
        "    print('list of Jobs failed to get Posted', fail_record)\n",
        "    data_list_for_failed = pd.read_csv(filename_failed)\n",
        "\n",
        "    failed_jobs = []\n",
        "    for j in fail_index:\n",
        "        failed_jobs_dict = data_list_for_failed.iloc[j].to_dict()\n",
        "        failed_jobs.append(failed_jobs_dict)\n",
        "    if fail_count > 0: \n",
        "        fd = pd.DataFrame(failed_jobs)\n",
        "        filename_failed = 'failed_jobs_' + str(try_) + '.csv'\n",
        "        fd.to_csv(filename_failed,index=False,header=True)\n",
        "    elif fail_countt == -1:\n",
        "        pass\n",
        "    else:\n",
        "        print(\"\\nCongratulations, you did posted all jobs from MonsterIndia for your Given Task/Company\")\n",
        "        \n",
        "    posting_start = 2\n",
        "    return fail_count, filename_failed, fail_countt, posting_start"
      ],
      "id": "zS6oljVQ4xM4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54db8ccc"
      },
      "source": [
        "#Posting function is getting call from this cell....\n",
        "#From this cell we are posting jobs from main csv file\n",
        "filename_failed = filename\n",
        "dlst = pd.read_csv(filename_failed).values.tolist()\n",
        "last_posting = len(dlst) + 1\n",
        "#Do not change lines above \n",
        "\n",
        "\n",
        "posting_start = 2               #Enter row no. to start posting from that row of CSV file(defaultly give 2, as first job is at row-2 in CSV)\n",
        "#last_posting = 10              #If you want to give end range for posting, remove '#' symbol on starting of this line & replace 10 to certain number jobs...\n",
        "                                    #give number like till which job/row(including) in csv you want to post in one execution.\n",
        "\n",
        "\n",
        "#Calling Function\n",
        "for i in range(0, 10):\n",
        "\n",
        "    p = posting_failed(filename_failed, i, posting_start, last_posting)\n",
        "    filename_failed = p[1]\n",
        "    posting_start = p[3]\n",
        "    if p[0] == 0:\n",
        "        break\n",
        "    elif p[2] == -1:\n",
        "        break\n",
        "    elif i == 9:\n",
        "        print('We tried 10 times, if you seeing this msg. You need to contact Group/Team leader')\n",
        "        break\n",
        "    print(f\"\\n\\nTrying {i+2}th time Again for all failed jobs\\n\\n\")\n",
        "    time.sleep(5)\n"
      ],
      "id": "54db8ccc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3sSeC0bcmr2"
      },
      "source": [
        "                             # ------------ This cell is only need to run when your upper cell o/p is   \"Cell Execution Terminated...\"  ----------------\n",
        "\n",
        "#                          ***Failed function is getting call from this cell....***\n",
        "                            \n",
        "\n",
        "#Run this cell only if you got \"Cell Execution Terminated...\" output of above cell\n",
        "#From this cell we are posting jobs from 'failed_job_0.csv' file\n",
        "\n",
        "filename_failed = 'failed_jobs_0.csv'\n",
        "dlst = pd.read_csv(filename_failed).values.tolist()\n",
        "last_posting = len(dlst) + 1\n",
        "posting_start = 2              \n",
        "            \n",
        "#Calling Function\n",
        "for i in range(0, 10):\n",
        "\n",
        "    p = posting_failed(filename_failed, i, posting_start, last_posting)\n",
        "    filename_failed = p[1]\n",
        "    posting_start = p[3]\n",
        "    if p[0] == 0:\n",
        "        break\n",
        "    elif p[2] == -1:\n",
        "        break\n",
        "    elif i == 9:\n",
        "        print('We tried 10 times, if you seeing this msg. You need to contact Group/Team leader')\n",
        "        break\n",
        "    print(f\"\\n\\nTrying {i+2}th time Again for all failed jobs\\n\\n\")\n",
        "    time.sleep(5)"
      ],
      "id": "E3sSeC0bcmr2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBpfyaMDbHg0"
      },
      "source": [],
      "id": "KBpfyaMDbHg0",
      "execution_count": null,
      "outputs": []
    }
  ]
}